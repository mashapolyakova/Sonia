{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import utils\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def durationClass(duration):\n",
    "    if (duration <= 0.25):\n",
    "        return 0\n",
    "    if (duration < 0.45):\n",
    "        return 1\n",
    "    if (duration < 0.6):\n",
    "        return 2\n",
    "    if (duration < 0.8):\n",
    "        return 3\n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetNums(mid):\n",
    "    durations = dict.fromkeys([i for i in range(128)], 0)\n",
    "    timer = 0.0\n",
    "    lastAppear = []\n",
    "    for i in range(128):\n",
    "        lastAppear.append(0)\n",
    "        musicToIndexes = []\n",
    "    currentIndex = 0;\n",
    "    for msg in mid.play(meta_messages=True):\n",
    "        timer += msg.time\n",
    "        if (msg.type == \"note_on\"):\n",
    "            musicToIndexes.append(msg.note)\n",
    "            durations[msg.note] = timer\n",
    "            lastAppear[msg.note] = currentIndex\n",
    "            currentIndex += 1\n",
    "        if (msg.type == \"note_off\"):\n",
    "            duration = timer - durations[msg.note]\n",
    "            typeDuration = durationClass(duration)\n",
    "            musicToIndexes[lastAppear[msg.note]] = msg.note + 128* typeDuration\n",
    "    return musicToIndexes, mid.ticks_per_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indexToNote(index):\n",
    "    decoder = {}\n",
    "    for i in range(128):\n",
    "        for j in range(5):\n",
    "            decoder[i + j*128] = [i, j]\n",
    "    return decoder[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mido import Message, MidiFile, MidiTrack\n",
    "def toMidi(Indexes, ticks):\n",
    "    #print(Indexes)\n",
    "    moments = [[] for i in range(len(Indexes) + 4)]\n",
    "    current = 0\n",
    "    for note in Indexes:\n",
    "        decoded = indexToNote(note)\n",
    "        moments[current].append(decoded[0])\n",
    "        #print(current, decoded[1], len(Indexes))\n",
    "        moments[current + decoded[1]].append(-decoded[0])\n",
    "        current += 1\n",
    "    newMid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    newMid.tracks.append(track)\n",
    "    tick_time = round(ticks* 0.1) * 2\n",
    "    for moment in moments:\n",
    "        for ivent in moment:\n",
    "            if (ivent < 0):\n",
    "                track.append(Message('note_off', note=-ivent, velocity=0, time=tick_time))\n",
    "            else:\n",
    "                track.append(Message('note_on', note=ivent, velocity=64, time=tick_time))\n",
    "    return newMid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, decoder, decoder_optimizer, criterion, max_length=1000):\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "\n",
    "    decoder_hidden = input_tensor\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            #print(decoder_input)\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di:di+1])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di:di+1])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainIters(n_iters, musicIndexes, decoder, print_every=20, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    " \n",
    "        \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        input_tensor = []\n",
    "        for i in range(hidden_size):\n",
    "            input_tensor.append(random.randint(1, 10))\n",
    "        input_tensor = np.reshape(input_tensor, (1, 1, hidden_size))\n",
    "        input_tensor = torch.Tensor(input_tensor.tolist())\n",
    "        x = musicIndexes[iter%12]\n",
    "        x = torch.LongTensor(x)\n",
    "        #print(x)\n",
    "        loss = train(input_tensor, x, decoder, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "    \n",
    "\n",
    "#         if iter % plot_every == 0:\n",
    "#             plot_loss_avg = plot_loss_total / plot_every\n",
    "#             plot_losses.append(plot_loss_avg)\n",
    "#             plot_loss_total = 0\n",
    "\n",
    "#     showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'music' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-72c223b89425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmusicInd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusicToIndexes1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmiddle_tick\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmiddle_tick\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'music' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "hidden_size = 256\n",
    "output_size = 1000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "musicInd = []\n",
    "tracks =  [file for file in os.listdir(\"/home/maria/Documents/музычка/simpledata\")]\n",
    "middle_tick = 0\n",
    "for file in tracks:\n",
    "    mid1 = mido.MidiFile(\"/home/maria/Documents/музычка/simpledata/\" +file)\n",
    "    musicToIndexes1, ticks = GetNums(mid1)\n",
    "    musicInd.append(musicToIndexes1)\n",
    "    middle_tick += ticks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle_tick /= len(musicInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 0m 58s) (20 2%) 6.8901\n",
      "0m 2s (- 1m 0s) (40 4%) 6.2851\n",
      "0m 3s (- 1m 0s) (60 6%) 6.4852\n",
      "0m 4s (- 0m 57s) (80 8%) 5.5340\n",
      "0m 6s (- 0m 57s) (100 10%) 5.8142\n",
      "0m 7s (- 0m 56s) (120 12%) 5.8260\n",
      "0m 8s (- 0m 54s) (140 14%) 4.8918\n",
      "0m 10s (- 0m 54s) (160 16%) 5.4124\n",
      "0m 11s (- 0m 54s) (180 18%) 5.3404\n",
      "0m 13s (- 0m 54s) (200 20%) 4.9011\n",
      "0m 15s (- 0m 55s) (220 22%) 4.8949\n",
      "0m 17s (- 0m 55s) (240 24%) 5.3875\n",
      "0m 19s (- 0m 54s) (260 26%) 4.6340\n",
      "0m 21s (- 0m 54s) (280 28%) 4.5702\n",
      "0m 22s (- 0m 53s) (300 30%) 5.0116\n",
      "0m 24s (- 0m 52s) (320 32%) 4.6099\n",
      "0m 26s (- 0m 51s) (340 34%) 4.7530\n",
      "0m 28s (- 0m 50s) (360 36%) 5.4230\n",
      "0m 30s (- 0m 49s) (380 38%) 4.8984\n",
      "0m 31s (- 0m 47s) (400 40%) 4.6678\n",
      "0m 33s (- 0m 46s) (420 42%) 5.5885\n",
      "0m 35s (- 0m 44s) (440 44%) 4.9383\n",
      "0m 37s (- 0m 43s) (460 46%) 4.7654\n",
      "0m 39s (- 0m 42s) (480 48%) 5.0973\n",
      "0m 40s (- 0m 40s) (500 50%) 5.3735\n",
      "0m 42s (- 0m 39s) (520 52%) 4.9131\n",
      "0m 44s (- 0m 37s) (540 54%) 7.2161\n",
      "0m 45s (- 0m 35s) (560 56%) 6.0669\n",
      "0m 47s (- 0m 34s) (580 57%) 5.5519\n",
      "0m 49s (- 0m 32s) (600 60%) 7.0639\n",
      "0m 50s (- 0m 31s) (620 62%) 5.4509\n",
      "0m 52s (- 0m 29s) (640 64%) 6.2125\n",
      "0m 54s (- 0m 28s) (660 66%) 7.5175\n",
      "0m 56s (- 0m 26s) (680 68%) 6.6267\n",
      "0m 58s (- 0m 24s) (700 70%) 6.3589\n",
      "0m 59s (- 0m 23s) (720 72%) 7.0891\n",
      "1m 1s (- 0m 21s) (740 74%) 6.7484\n",
      "1m 3s (- 0m 20s) (760 76%) 7.0014\n",
      "1m 5s (- 0m 18s) (780 78%) 7.6900\n",
      "1m 6s (- 0m 16s) (800 80%) 7.2568\n",
      "1m 8s (- 0m 15s) (820 82%) 6.3574\n",
      "1m 10s (- 0m 13s) (840 84%) 8.7349\n",
      "1m 11s (- 0m 11s) (860 86%) 7.0003\n",
      "1m 13s (- 0m 10s) (880 88%) 7.1073\n",
      "1m 15s (- 0m 8s) (900 90%) 7.6450\n",
      "1m 16s (- 0m 6s) (920 92%) 7.4880\n",
      "1m 18s (- 0m 5s) (940 94%) 6.1512\n",
      "1m 20s (- 0m 3s) (960 96%) 7.3633\n",
      "1m 22s (- 0m 1s) (980 98%) 6.2664\n",
      "1m 23s (- 0m 0s) (1000 100%) 5.8823\n"
     ]
    }
   ],
   "source": [
    "# elements = 0\n",
    "# for elem in musicInd:\n",
    "#     size = 0\n",
    "#     for el in elem:\n",
    "#         size+=1\n",
    "#     print(size)\n",
    "#     elements += 1\n",
    "#     print(elem)\n",
    "# print(elements)\n",
    "decoder = DecoderRNN(hidden_size, output_size)\n",
    "trainIters(1000, musicInd, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(input_tensor, decoder, prob, max_length=100):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_tensor = torch.FloatTensor(input_tensor)\n",
    "        decoder_input = torch.tensor([[SOS_token]])  # SOS\n",
    "\n",
    "        decoder_hidden = input_tensor\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(prob)\n",
    "            item = random.randint(0, prob - 1)\n",
    "            \n",
    "            topv = topv[0][item]\n",
    "            topi = topi[0][item]\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(topi.item())\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sample():\n",
    "    begin = []\n",
    "    note = random.randint(1, 10)\n",
    "    for i in range(256):\n",
    "        begin.append(note)\n",
    "#     for i in range(256):\n",
    "#         begin.append(random.randint(200, 240))\n",
    "    begin = np.reshape(begin, (1,1, 256))\n",
    "    print(\"begin_predict\")\n",
    "    generated = evaluate(begin, decoder, 20)\n",
    "    mid = toMidi(generated, middle_tick)\n",
    "    mid.save('generated1.mid')\n",
    "#generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.5/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type DecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(decoder, \"/home/maria/Documents/Sonia/decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "output_size = 1000\n",
    "decoder = DecoderRNN(hidden_size, output_size)\n",
    "decoder = torch.load(\"/home/maria/Documents/Sonia/decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin_predict\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "output_size = 1000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "middle_tick = 48*16\n",
    "generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "hidden_size = 256\n",
    "output_size = 1000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "musicInd = []\n",
    "tracks =  [file for file in os.listdir(\"/home/maria/Downloads/chaikovskiy/tschai\")]\n",
    "middle_tick = 0\n",
    "for file in tracks:\n",
    "    mid1 = mido.MidiFile(\"/home/maria/Downloads/chaikovskiy/tschai/\" +file)\n",
    "    musicToIndexes1, ticks = GetNums(mid1)\n",
    "    musicInd.append(musicToIndexes1)\n",
    "    middle_tick += ticks\n",
    "\n",
    "middle_tick /= len(musicInd)\n",
    "# elements = 0\n",
    "# for elem in musicInd:\n",
    "#     size = 0\n",
    "#     for el in elem:\n",
    "#         size+=1\n",
    "#     print(size)\n",
    "#     elements += 1\n",
    "#     print(elem)\n",
    "# print(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(musicInd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 29s (- 72m 51s) (20 2%) 4.4111\n",
      "2m 58s (- 71m 32s) (40 4%) 4.1384\n",
      "4m 32s (- 71m 7s) (60 6%) 3.9887\n",
      "6m 9s (- 70m 47s) (80 8%) 3.7589\n",
      "7m 38s (- 68m 46s) (100 10%) 3.5785\n",
      "9m 11s (- 67m 23s) (120 12%) 3.4724\n",
      "10m 47s (- 66m 19s) (140 14%) 3.5061\n",
      "12m 18s (- 64m 39s) (160 16%) 3.4317\n",
      "13m 54s (- 63m 20s) (180 18%) 3.4218\n",
      "15m 31s (- 62m 6s) (200 20%) 3.4535\n",
      "17m 3s (- 60m 28s) (220 22%) 3.7220\n",
      "18m 37s (- 58m 57s) (240 24%) 3.9594\n",
      "20m 14s (- 57m 36s) (260 26%) 4.3618\n",
      "21m 43s (- 55m 52s) (280 28%) 4.2166\n",
      "23m 17s (- 54m 20s) (300 30%) 4.0377\n",
      "24m 54s (- 52m 56s) (320 32%) 3.9607\n",
      "26m 23s (- 51m 14s) (340 34%) 3.9729\n",
      "27m 56s (- 49m 41s) (360 36%) 3.6346\n",
      "29m 33s (- 48m 13s) (380 38%) 3.6113\n",
      "31m 3s (- 46m 34s) (400 40%) 3.7435\n",
      "32m 38s (- 45m 4s) (420 42%) 3.9586\n",
      "34m 16s (- 43m 37s) (440 44%) 3.9106\n",
      "35m 46s (- 41m 59s) (460 46%) 3.7438\n",
      "37m 18s (- 40m 24s) (480 48%) 3.7087\n",
      "38m 55s (- 38m 55s) (500 50%) 3.5003\n",
      "40m 25s (- 37m 18s) (520 52%) 3.4753\n",
      "41m 58s (- 35m 45s) (540 54%) 3.5220\n",
      "43m 34s (- 34m 14s) (560 56%) 3.5936\n",
      "45m 2s (- 32m 36s) (580 57%) 3.5375\n",
      "46m 34s (- 31m 2s) (600 60%) 3.5637\n",
      "48m 8s (- 29m 30s) (620 62%) 3.6917\n",
      "49m 36s (- 27m 54s) (640 64%) 3.6170\n",
      "51m 8s (- 26m 20s) (660 66%) 3.4427\n",
      "52m 42s (- 24m 48s) (680 68%) 3.6611\n",
      "54m 10s (- 23m 12s) (700 70%) 3.8021\n",
      "55m 41s (- 21m 39s) (720 72%) 3.8281\n",
      "57m 16s (- 20m 7s) (740 74%) 3.8000\n",
      "78m 6s (- 24m 40s) (760 76%) 3.7182\n",
      "79m 39s (- 22m 28s) (780 78%) 3.6138\n",
      "81m 15s (- 20m 18s) (800 80%) 3.6136\n",
      "82m 44s (- 18m 9s) (820 82%) 3.6273\n",
      "84m 18s (- 16m 3s) (840 84%) 3.4852\n",
      "85m 53s (- 13m 58s) (860 86%) 3.4231\n",
      "87m 21s (- 11m 54s) (880 88%) 3.4189\n",
      "88m 54s (- 9m 52s) (900 90%) 3.3388\n",
      "90m 30s (- 7m 52s) (920 92%) 3.2733\n",
      "91m 58s (- 5m 52s) (940 94%) 3.2171\n",
      "93m 30s (- 3m 53s) (960 96%) 3.3540\n",
      "95m 7s (- 1m 56s) (980 98%) 3.2840\n",
      "96m 41s (- 0m 0s) (1000 100%) 3.2924\n"
     ]
    }
   ],
   "source": [
    "decoder = DecoderRNN(hidden_size, output_size)\n",
    "trainIters(1000, musicInd, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin_predict\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "output_size = 1000\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480.0\n"
     ]
    }
   ],
   "source": [
    "print(middle_tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/anaconda3/lib/python3.5/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type DecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(decoder, \"/home/maria/Documents/Sonia/decoder_tchaik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = torch.load(\"/home/maria/Documents/Sonia/decoder_tchaik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(1000, 256)\n",
      "  (gru): GRU(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=1000, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
